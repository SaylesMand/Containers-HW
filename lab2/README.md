## Архитектура
Проект состоит из трёх сервисов:

### 1. **postgres** - База данных
- **Образ:** `postgres:18-alpine`
- **Назначение:** Хранение метаданных Airflow
- **Порт:** `5432` (доступен снаружи)
- **Особенности:**
  - Настроен healthcheck для проверки готовности БД
  - Данные сохраняются в named volume `postgres_data`
  - Все параметры подключения загружаются из `.env`

### 2. **airflow-init** - Инициализация (init-контейнер)
- **Образ:** `airflow-custom:latest` (собирается из локального Dockerfile)
- **Назначение:** Одноразовая инициализация базы данных Airflow
- **Команда:** `airflow db migrate`
- **Особенности:**
  - Автоматически собирается из `Dockerfile`
  - Запускается только после успешного healthcheck PostgreSQL
  - Выполняется один раз (`restart: "no"`)
  - После завершения контейнер останавливается

### 3. **airflow** - Основное приложение
- **Образ:** `airflow-custom:latest` (использует уже собранный образ)
- **Назначение:** Запуск веб-интерфейса и scheduler Airflow
- **Порт:** `8080` (веб-интерфейс)
- **Команда:** `airflow standalone`
- **Особенности:**
  - Запускается только после успешного завершения `airflow-init`
  - Работает постоянно (`restart: always`)
  - Монтирует папки `dags/` и `plugins/` для разработки
  - Данные хранятся в volume `airflow_data`

## Volumes

- **postgres_data** - Хранит данные PostgreSQL
- **airflow_data** - Хранит данные Airflow (логи, конфигурация)
- **./dags** - Bind mount для DAG файлов (разработка)
- **./plugins** - Bind mount для плагинов (разработка)

## Network

Все сервисы подключены к единой сети `airflow-net` (bridge driver), что обеспечивает:
- Изоляцию от других Docker контейнеров
- Взаимодействие между сервисами по именам контейнеров

## Запуск проекта

```bash

# 1. Собрать и запустить все сервисы
docker-compose up -d --build

# 2. Проверить логи
docker-compose logs -f

# 3. Получить пароль администратора
docker exec airflow cat /opt/airflow/simple_auth_manager_passwords.json.generated

# 4. Открыть веб-интерфейс
# http://localhost:8080
```